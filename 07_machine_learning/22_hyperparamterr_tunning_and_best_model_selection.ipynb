{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the best model with Best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# train test split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# import regression algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "#import grid search cv for cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import preprocessors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rergression Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features and variables\n",
    "X = df.drop('tip', axis=1)\n",
    "y = df['tip']\n",
    "\n",
    "# label encode categorical variables\n",
    "le = LabelEncoder()\n",
    "X['sex'] = le.fit_transform(X['sex'])\n",
    "X['smoker'] = le.fit_transform(X['smoker'])\n",
    "X['day'] = le.fit_transform(X['day'])\n",
    "X['time'] = le.fit_transform(X['time'])\n",
    "\n",
    "# split the data into train and test data with 80% training dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute error for SVR is  0.57\n",
      "Mean Absolute error for LinearRegression is  0.67\n",
      "Mean Absolute error for KNeighborsRegressor is  0.73\n",
      "Mean Absolute error for GradientBoostingRegressor is  0.73\n",
      "Mean Absolute error for RandomForestRegressor is  0.77\n",
      "Mean Absolute error for XGBRegressor is  0.80\n",
      "Mean Absolute error for DecisionTreeRegressor is  0.89\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionaries of list of models to evaluate performance\n",
    "models = { \n",
    "          'LinearRegression' : LinearRegression(),\n",
    "          'SVR' : SVR(),\n",
    "          'DecisionTreeRegressor' : DecisionTreeRegressor(),\n",
    "          'RandomForestRegressor' : RandomForestRegressor(),\n",
    "          'KNeighborsRegressor' : KNeighborsRegressor(),\n",
    "          'GradientBoostingRegressor' : GradientBoostingRegressor(),\n",
    "          'XGBRegressor' : XGBRegressor()          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "model_scores = []\n",
    "for name, model in models.items():\n",
    "    # fit each model from models on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = model.predict(X_test)\n",
    "    metric = mean_absolute_error(y_test, y_pred)\n",
    "    model_scores.append((name, metric))\n",
    "    \n",
    "      \n",
    "    # # print the performing metric\n",
    "    # print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    # print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    # print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    # print('\\n')\n",
    "# selecting the best model from all above models with evaluation metrics sorting method\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=False)\n",
    "for model in sorted_models:\n",
    "    print('Mean Absolute error for', f\"{model[0]} is {model[1]: .2f}\") \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Assignment:** Find the best model based on each metrics from above mentioned results?  with Diamonds dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression MSE:  0.6948129686287711\n",
      "LinearRegression R2:  0.4441368826121931\n",
      "LinearRegression MAE:  0.6703807496461157\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionaries of list of models to evaluate performance with hyperparameters\n",
    "models = { \n",
    "          'LinearRegression' : (LinearRegression(), {}),\n",
    "          'SVR' : (SVR(), {'kernel': ['rbf', 'poly', 'sigmoid'], 'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01], 'epsilon': [0.1, 0.01, 0.001]}),\n",
    "          'DecisionTreeRegressor' : (DecisionTreeRegressor(), {'max_depth': [None, 5, 10], 'splitter': ['best', 'random']}),\n",
    "          'RandomForestRegressor' : (RandomForestRegressor(), {'n_estimators': [10, 100, 1000], 'max_depth': [None, 5, 10]}),\n",
    "          'KNeighborsRegressor' : (KNeighborsRegressor(), {'n_neighbors': np.arange(3, 100, 2), 'weights': ['uniform', 'distance']}),\n",
    "          'GradientBoostingRegressor' : (GradientBoostingRegressor(), {'loss': ['ls', 'lad', 'huber', 'quantile'], 'n_estimators': [10, 100, 1000]}),\n",
    "          'XGBRegressor' : (XGBRegressor(), {'n_estimators': [10, 100, 1000], 'learning_rate': [0.1, 0.01, 0.001]}),          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    # create a pipline\n",
    "    pipeline = GridSearchCV(model, params, cv=5)\n",
    "    \n",
    "    # fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "      \n",
    "    # print the performing metric\n",
    "    print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: How to get best parameters of each model, write in the for loop among the code, how to get best model out of it?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression MSE: 0.6948129686287711\n",
      "LinearRegression R2: 0.4441368826121931\n",
      "LinearRegression MAE: 0.6703807496461157\n",
      "\n",
      "SVR MSE: 0.795653498186258\n",
      "SVR R2: 0.3634626096067757\n",
      "SVR MAE: 0.6669221028004211\n",
      "\n",
      "DecisionTreeRegressor MSE: 0.987431694689693\n",
      "DecisionTreeRegressor R2: 0.21003653529818433\n",
      "DecisionTreeRegressor MAE: 0.7347691165599329\n",
      "\n",
      "RandomForestRegressor MSE: 0.911224685109292\n",
      "RandomForestRegressor R2: 0.27100354055682807\n",
      "RandomForestRegressor MAE: 0.7463857608727101\n",
      "\n",
      "KNeighborsRegressor MSE: 0.6437675304097399\n",
      "KNeighborsRegressor R2: 0.4849741693324664\n",
      "KNeighborsRegressor MAE: 0.6385880398456918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingRegressor must be a str among {'absolute_error', 'huber', 'squared_error', 'quantile'}. Got 'ls' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingRegressor must be a str among {'absolute_error', 'huber', 'squared_error', 'quantile'}. Got 'lad' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "  0.24496317  0.30510313  0.10550829 -0.96717201 -0.37172471 -0.36067534]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor MSE: 0.7916520563916473\n",
      "GradientBoostingRegressor R2: 0.3666638364266893\n",
      "GradientBoostingRegressor MAE: 0.7142653506730012\n",
      "\n",
      "XGBRegressor MSE: 0.8677490675057522\n",
      "XGBRegressor R2: 0.30578483195839323\n",
      "XGBRegressor MAE: 0.7584847906657628\n",
      "\n",
      "Best Model: KNeighborsRegressor(n_neighbors=21, weights='distance')\n",
      "Best MSE: 0.6437675304097399\n",
      "Best R2: 0.4849741693324664\n",
      "Best MAE: 0.6385880398456918\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of models with hyperparameters to evaluate\n",
    "models = {\n",
    "    'LinearRegression': (LinearRegression(), {}),\n",
    "    'SVR': (SVR(), {'kernel': ['rbf', 'poly', 'sigmoid'], 'C': [0.1, 1], 'gamma': [1, 0.1], 'epsilon': [0.1, 0.01]}),\n",
    "    'DecisionTreeRegressor': (DecisionTreeRegressor(), {'max_depth': [None, 5, 10], 'splitter': ['best', 'random']}),\n",
    "    'RandomForestRegressor': (RandomForestRegressor(), {'n_estimators': [10, 100], 'max_depth': [None, 5, 10]}),\n",
    "    'KNeighborsRegressor': (KNeighborsRegressor(), {'n_neighbors': np.arange(3, 100, 2), 'weights': ['uniform', 'distance']}),\n",
    "    'GradientBoostingRegressor': (GradientBoostingRegressor(), {'loss': ['ls', 'lad', 'huber', 'quantile'], 'n_estimators': [10, 100, 1000]}),\n",
    "    'XGBRegressor': (XGBRegressor(), {'n_estimators': [10, 100], 'learning_rate': [0.1, 0.01]}),\n",
    "}\n",
    "\n",
    "# Initialize variables to track the best model and its performance\n",
    "best_model = None\n",
    "best_mse = float('inf')\n",
    "best_r2 = -float('inf')\n",
    "best_mae = float('inf')\n",
    "\n",
    "# Iterate over each model, train, predict, and evaluate performance metrics\n",
    "for name, (model, params) in models.items():\n",
    "    # Create a pipeline with the model\n",
    "    pipeline = GridSearchCV(model, params, cv=5)\n",
    "    \n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    # Print the performance metrics\n",
    "    print(name, 'MSE:', mse)\n",
    "    print(name, 'R2:', r2)\n",
    "    print(name, 'MAE:', mae)\n",
    "    print()\n",
    "    \n",
    "    # Check if this model has better performance\n",
    "    if mse < best_mse:\n",
    "        best_model = pipeline\n",
    "        best_mse = mse\n",
    "        best_r2 = r2\n",
    "        best_mae = mae\n",
    "\n",
    "# Print the best model's performance metrics\n",
    "print('Best Model:', best_model.best_estimator_)\n",
    "print('Best MSE:', best_mse)\n",
    "print('Best R2:', best_r2)\n",
    "print('Best MAE:', best_mae)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Add preprocessor inside the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a preprocessor\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=['numeric_scaling', StandardScaler(), ['total_bill', 'size']], remainder='passthrough')\n",
    "\n",
    "\n",
    "# Create a dictionaries of list of models to evaluate performance with hyperparameters\n",
    "models = { \n",
    "          'LinearRegression' : (LinearRegression(), {}),\n",
    "          'SVR' : (SVR(), {'kernel': ['rbf', 'poly', 'sigmoid'], 'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01], 'epsilon': [0.1, 0.01, 0.001]}),\n",
    "          'DecisionTreeRegressor' : (DecisionTreeRegressor(), {'max_depth': [None, 5, 10], 'splitter': ['best', 'random']}),\n",
    "          'RandomForestRegressor' : (RandomForestRegressor(), {'n_estimators': [10, 100, 1000], 'max_depth': [None, 5, 10]}),\n",
    "          'KNeighborsRegressor' : (KNeighborsRegressor(), {'n_neighbors': np.arange(3, 100, 2), 'weights': ['uniform', 'distance']}),\n",
    "          'GradientBoostingRegressor' : (GradientBoostingRegressor(), {'loss': ['ls', 'lad', 'huber', 'quantile'], 'n_estimators': [10, 100, 1000]}),\n",
    "          'XGBRegressor' : (XGBRegressor(), {'n_estimators': [10, 100, 1000], 'learning_rate': [0.1, 0.01, 0.001]}),          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    # create a pipline with preprocessor\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])   \n",
    "    \n",
    "    # make a grid search cv to tune the hyperparameter\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5)\n",
    "    \n",
    "    \n",
    "    # fit the pipeline\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "      \n",
    "    # print the performing metric\n",
    "    print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/babaaammar/mambaforge/envs/python_ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "Mean Accuracy: 0.9733333333333334\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Mean Accuracy: 0.9533333333333335\n",
      "\n",
      "Classifier: Random Forest\n",
      "Mean Accuracy: 0.9600000000000002\n",
      "\n",
      "Classifier: SVM\n",
      "Mean Accuracy: 0.9666666666666668\n",
      "\n",
      "Classifier: KNN\n",
      "Mean Accuracy: 0.9733333333333334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create a dictionary of classifiers to evaluate\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Perform k-fold cross-validation and calculate the mean accuracy\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    scores = cross_val_score(classifier, X, y, cv=kfold)\n",
    "    accuracy = np.mean(scores)\n",
    "    print(\"Classifier:\", name)\n",
    "    print(\"Mean Accuracy:\", accuracy)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
